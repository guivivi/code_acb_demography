url_player1 <- sapply(strsplit(url_player, '\\/ver*.'), `[`, 2)
url_player2 <- gsub("-.*", "", url_player1)
stats_game1 <- stats_game %>%
mutate(CombinID = url_player2, .after = Website)
# Join home and away
stats_game <- rbind(stats_home3, stats_away3) %>%
mutate(GS = ifelse(grepl("\\*", Number), 1, 0), .after = Number) %>%
separate(TwoP, c("TwoP", "TwoPA"), sep = "/", fill = "left") %>%
separate(ThreeP, c("ThreeP", "ThreePA"), sep = "/", fill = "left") %>%
separate(FT, c("FT", "FTA"), sep = "/", fill = "left") %>%
separate(RB, c("DRB", "ORB"), sep = "\\+", fill = "left") %>%
mutate_at(vars(contains("Perc")), ~gsub("%", "", .)) %>%
mutate(Season = season,
Type_season = type_season,
Day = gsub("JORNADA ", "", url_data1[1]),
Date = url_data1[2],
Game = tolower(gsub("-", " - ", teams1)),
GameRes = res,
GameID = game_id,
Website = url_link) %>%
relocate(Team, .after = GameRes) %>%
mutate(Periods = paste(score2, collapse = " ; "),
Time = url_data1[3],
Place = url_data1[4],
Audience = url_data1[5],
Referees = url_refs1)
stats_game[is.na(stats_game)] <- 0
# PLAYERS:
url_player <- read_html(url_link) %>%
html_nodes(xpath = './/td[@class="nombre jugador ellipsis"]') %>%
as.character()
url_player1 <- sapply(strsplit(url_player, '\\/ver*.'), `[`, 2)
url_player2 <- gsub("-.*", "", url_player1)
stats_game1 <- stats_game %>%
mutate(CombinID = url_player2, .after = Website)
url_player2
# Join home and away
stats_game <- rbind(stats_home3, stats_away3) %>%
mutate(GS = ifelse(grepl("\\*", Number), 1, 0), .after = Number) %>%
separate(TwoP, c("TwoP", "TwoPA"), sep = "/", fill = "left") %>%
separate(ThreeP, c("ThreeP", "ThreePA"), sep = "/", fill = "left") %>%
separate(FT, c("FT", "FTA"), sep = "/", fill = "left") %>%
separate(RB, c("DRB", "ORB"), sep = "\\+", fill = "left") %>%
mutate_at(vars(contains("Perc")), ~gsub("%", "", .)) %>%
mutate(Season = season,
Type_season = type_season,
Day = gsub("JORNADA ", "", url_data1[1]),
Date = url_data1[2],
Game = tolower(gsub("-", " - ", teams1)),
GameRes = res,
GameID = game_id,
Website = url_link) %>%
relocate(Team, .after = GameRes) %>%
mutate(Periods = paste(score2, collapse = " ; "),
Time = url_data1[3],
Place = url_data1[4],
Audience = url_data1[5],
Referees = url_refs1) %>%
relocate(Coach, .after = Website)
stats_game[is.na(stats_game)] <- 0
View(stats_game)
# SCRAPE GAMES' DATA:
code <- "101266"
url_base <- "http://www.acb.com/partido/estadisticas/id/"
url_link <- paste(url_base, code, sep = "")
url_html <- read_html(url_link)
# PLAYERS:
url_player <- read_html(url_link) %>%
html_nodes(xpath = './/td[@class="nombre jugador ellipsis"]') %>%
as.character()
url_player1 <- sapply(strsplit(url_player, '\\/ver*.'), `[`, 2)
url_player2 <- gsub("-.*", "", url_player1)
url_player2
stats_game1 <- stats_game %>%
mutate(CombinID = url_player2, .after = Website)
View(stats_game1)
colnames(stats_game1)
colnames(acb_games_1718)
code = stats_game1$CombinID1
code = stats_game1$CombinID[1]
code
unique(stats_game1$CombinID)
# code <- "30000004"
players_code_aux <- unique(stats_game1$CombinID)
players_code <- players_code_aux[!is.na(players_code_aux)]
players_code
players_name_aux <- unique(stats_game1$Player)
players_name_aux
players_name[players_name_aux != "Equipo"]
players_name <- players_name_aux[players_name_aux != "Equipo"]
players_name
install.packages("RSelenium")
install.packages("XML")
install.packages("XML")
devtools::install_github("r-lib/xml2")
install.packages("RSelenium")
install.packages("XML")
devtools::install_github('bziarkowski/euRobasket')
devtools::install_github('bziarkowski/euRobasket')
load("/home/guillevinue/Downloads/euRobasket-master/data/fibalivestats_matches_ids.rda")
View(fibalivestats_matches_ids)
load("/home/guillevinue/Downloads/euRobasket-master/data/livefibaeurope_matches_ids.rda")
View(livefibaeurope_matches_ids)
load("/home/guillevinue/Downloads/euRobasket-master/data/leagues_ids.rda")
View(leagues_ids)
View(leagues_ids)
source('~/Downloads/euRobasket-master/R/get_shots_data_livefibaeurope.R', echo=TRUE)
gv <- get_shots_data_livefibaeurope(742430)
gameid = 742430
#Load from live.fibaeurope.com
url <- paste("http://live.fibaeurope.com/www/ShotChart.ashx?acc=5&lng=en&gameID=",gameid,"", sep = "")
url
install.packages("splashr")
install.packages("magick")
citation()
install.packages("AdvancedBasketballStats")
citation("AdvancedBasketballStats")
devtools::install_github("solmos/eurolig")
devtools::install_github("solmos/eurolig")
devtools::install_github("solmos/eurolig")
install.packages("NBAloveR")
citation("NBAloveR")
citation("nbaTools")
devtools::install_github("ccagrawal/nbaTools")
fechas <- c("2020-09-04", "2020-09-29", "2020-09-29", "2020-10-29", "2020-11-30",
"2020-12-31", "2021-01-29", "2021-03-01")
pago <- c(19.96, 1.33, 16.07, 37.99, 19, 19, 38.42, 19)
df0 <- data.frame(fecha = fechas, pago = pago)
df0
mean(df0$pago)
pago <- c(19.96, 1.33, 16.07, 37.99, 19, 19, 38.42, 19, 48.60)
df0 <- data.frame(fecha = fechas, pago = pago)
fechas <- c("2020-09-04", "2020-09-29", "2020-09-29", "2020-10-29", "2020-11-30",
"2020-12-31", "2021-01-29", "2021-03-01", "2021-03-30")
df0 <- data.frame(fecha = fechas, pago = pago)
df0
mean(df0$pago)
tolower("COMPARATIVE CHARACTERISTICS OF THE PARAMETERS' CHANGES OF SKIN AND FAT FLEXURES THICKNESS OF EXTREMETIES AT YOUTH UNDER THE CONDITION OF HIGHER EDUCATION")
install.packages("flexdashboard")
install.packages("dplyr")
library(shiny)
library(dplyr)
ui <- fluidPage(
dataTableOutput('my_table'),
actionButton('change','Change query')
)
server <- function(input,output,session)
{
# the modal dialog where the user can enter the query details.
query_modal <- modalDialog(
title = "Important message",
selectInput('input_query','Select # cyl:',unique(mtcars$cyl)),
easyClose = F,
footer = tagList(
actionButton("run", "Run query")
)
)
# Show the model on start up ...
showModal(query_modal)
# ... or when user wants to change query
observeEvent(input$change,
{
showModal(query_modal)
})
# reactiveVal to store the dataset
my_dataset <- reactiveVal()
observeEvent(input$run, {
removeModal()
# Your query here
my_data <- mtcars %>% filter(cyl %in% input$input_query)
my_dataset(my_data)
})
# render the output
output$my_table <- renderDataTable(my_dataset())
}
shinyApp(ui,server)
source('~/.active-rstudio-document', echo=TRUE)
install.packages("shinyalert")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
install.packages("shinyWidgets")
install.packages("shinyWidgets")
factorial(5)
factorial(5) / (factorial(2) * factorial(3))
49^6
fechas <- c("2020-09-04", "2020-09-29", "2020-09-29", "2020-10-29", "2020-11-30",
"2020-12-31", "2021-01-29", "2021-03-01", "2021-03-30", "2021-04-29")
pago <- c(19.96, 1.33, 16.07, 37.99, 19, 19, 38.42, 19, 48.60, 18.42)
df0 <- data.frame(fecha = fechas, pago = pago)
df0
mean(df0$pago)
library(rvest)
library(httr)
library(stringr)
library(dplyr)
user_email <- "guillermovinue@gmail.com"
user_agent_goo <- "Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0"
year = 2020; compet = 1; day = 1;
url_base <- "http://www.acb.com/resultados-clasificacion/ver/temporada_id"
url_link <- paste(url_base, "/", year, "/competicion_id/", compet, "/jornada_numero/", day, sep = "")
link_content <- GET(url_link,
user_agent(str_c(user_agent_goo, R.version$version.string, sep = ", ")),
add_headers(from = user_email))
link_content$status
url_html <- read_html(url_link)
url_code <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]') %>%
extract(seq(1,18,2)) %>%
as.character()
url_code <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]') #%>%
url_code
url_code1
url_code[1]
library(xml2)
?extract
library(magrittr)
url_code <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]') %>%
extract(seq(1,18,2)) %>%
as.character()
url_code1 <- sapply(strsplit(url_code, '\\/id*.'), `[`, 2)
url_code2 <- gsub('\\" .*', "", url_code1)
url_code2
library(rvest)
library(httr)
library(stringr)
library(dplyr)
library(stringi)
library(purrr)
library(readr)
# SCRAPE PLAYERS' DATA:
scrape_new_acb_players <- function(code, name_player, user_email, user_agent_goo) {
url_base <- "http://www.acb.com/jugador/temporada-a-temporada/id/"
url_link <- paste(url_base, code, sep = "")
link_content <- GET(url_link,
user_agent(str_c(user_agent_goo, R.version$version.string, sep = ", ")),
add_headers(from = user_email))
if (link_content$status == 404) {
stop("URL not found. Please check if it exists.")
}else{
url_html <- read_html(url_link)
url_data <- url_html %>%
html_nodes(xpath = './/div[@class="f-l-a-100 contenedora_datos_basicos"]') %>%
html_text()
data_player <- strsplit(url_data, "\n")[[1]]
data_player1 <- stri_replace_all_charclass(data_player, "\\p{WHITE_SPACE}", "")
data_player2 <- data_player1[data_player1 != ""]
url_data_sec <- url_html %>%
html_nodes(xpath = './/div[@class="f-l-a-100 contenedora_datos_secundarios"]') %>%
html_text()
data_player_sec <- strsplit(url_data_sec, "\n")[[1]]
data_player_sec1 <- stri_replace_all_charclass(data_player_sec, "\\p{WHITE_SPACE}", "")
data_player_sec2 <- data_player_sec1[data_player_sec1 != ""]
url_foto <- url_html %>%
html_nodes("img") %>%
map(xml_attrs) %>%
map_df(~as.list(.)) %>%
filter(alt == "Foto Jugador" & !is.na(style)) %>%
pull(src)
url_foto1 <- paste("http:", url_foto, sep = "")
frame_player <- data.frame(CombinID = code,
Player = name_player,
# Remove accents:
Position = stri_trans_general(gsub(".*:", "",
data_player2[4]), "Latin-ASCII"),
Height = gsub(".*:", "", gsub("m", "", data_player2[5])),
Date_birth = gsub("\\(.*", "", gsub(".*:", "", data_player_sec2[3])),
Nationality = gsub(".*,", "", data_player_sec2[2]),
Website_player = url_link,
Website_picture = url_foto1)
return(data_player = frame_player)
}
}
# code <- "30000004"
stats_game1 <- list.files(pattern = "*.csv", full.names = TRUE) %>%
map_df(~read_csv(.)) %>%
arrange(Day)
# code <- "30000004"
stats_game1 <- list.files(pattern = "*.csv", full.names = TRUE) %>%
map_df(~read_csv(.)) #%>%
library(rvest)
library(httr)
library(stringr)
library(dplyr)
library(stringi)
library(purrr)
library(readr)
# SCRAPE PLAYERS' DATA:
scrape_new_acb_players <- function(code, name_player, user_email, user_agent_goo) {
url_base <- "http://www.acb.com/jugador/temporada-a-temporada/id/"
url_link <- paste(url_base, code, sep = "")
link_content <- GET(url_link,
user_agent(str_c(user_agent_goo, R.version$version.string, sep = ", ")),
add_headers(from = user_email))
if (link_content$status == 404) {
stop("URL not found. Please check if it exists.")
}else{
url_html <- read_html(url_link)
url_data <- url_html %>%
html_nodes(xpath = './/div[@class="f-l-a-100 contenedora_datos_basicos"]') %>%
html_text()
data_player <- strsplit(url_data, "\n")[[1]]
data_player1 <- stri_replace_all_charclass(data_player, "\\p{WHITE_SPACE}", "")
data_player2 <- data_player1[data_player1 != ""]
url_data_sec <- url_html %>%
html_nodes(xpath = './/div[@class="f-l-a-100 contenedora_datos_secundarios"]') %>%
html_text()
data_player_sec <- strsplit(url_data_sec, "\n")[[1]]
data_player_sec1 <- stri_replace_all_charclass(data_player_sec, "\\p{WHITE_SPACE}", "")
data_player_sec2 <- data_player_sec1[data_player_sec1 != ""]
url_foto <- url_html %>%
html_nodes("img") %>%
map(xml_attrs) %>%
map_df(~as.list(.)) %>%
filter(alt == "Foto Jugador" & !is.na(style)) %>%
pull(src)
url_foto1 <- paste("http:", url_foto, sep = "")
frame_player <- data.frame(CombinID = code,
Player = name_player,
# Remove accents:
Position = stri_trans_general(gsub(".*:", "",
data_player2[4]), "Latin-ASCII"),
Height = gsub(".*:", "", gsub("m", "", data_player2[5])),
Date_birth = gsub("\\(.*", "", gsub(".*:", "", data_player_sec2[3])),
Nationality = gsub(".*,", "", data_player_sec2[2]),
Website_player = url_link,
Website_picture = url_foto1)
return(data_player = frame_player)
}
}
user_email <- "guillermovinue@gmail.com"
user_agent_goo <- "Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0"
# code <- "30000004"
stats_games <- list.files(pattern = "*.csv", full.names = TRUE) %>%
map_df(~read_csv(.)) %>%
arrange(Day)
library(rvest)
library(httr)
library(stringr)
library(dplyr)
library(magrittr) # extract
# SCRAPE GAMES' CODES:
scrape_new_acb_code <- function(year = 2020, compet = 1, day = 1, user_email, user_agent_goo) {
url_base <- "http://www.acb.com/resultados-clasificacion/ver/temporada_id"
url_link <- paste(url_base, "/", year, "/competicion_id/", compet, "/jornada_numero/", day, sep = "")
link_content <- GET(url_link,
user_agent(str_c(user_agent_goo, R.version$version.string, sep = ", ")),
add_headers(from = user_email))
if (link_content$status == 404) {
stop("URL not found. Please check if it exists.")
}else{
url_html <- read_html(url_link)
url_code <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]') %>%
extract(seq(1,18,2)) %>%
as.character()
url_code1 <- sapply(strsplit(url_code, '\\/id*.'), `[`, 2)
url_code2 <- gsub('\\" .*', "", url_code1)
return(url_code2)
}
}
user_email <- "guillermovinue@gmail.com"
user_agent_goo <- "Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0"
#days <- 1:38 ; year <- 2020 # 2020-2021
days <- 1:23 ; year <- 2019 # 2019-2020
codes_day <- list()
for (i in 1:length(days)) {
cat("ITERATION:", i, "\n")
cat("DAY:", days[i], "\n")
codes_day[[i]] <- scrape_new_acb_code(year = year, compet = 1, day = days[i],
user_email, user_agent_goo)
Sys.sleep(5)
}
i
days[i]
year = year
compet = 1
day = days[i]
url_base <- "http://www.acb.com/resultados-clasificacion/ver/temporada_id"
url_link <- paste(url_base, "/", year, "/competicion_id/", compet, "/jornada_numero/", day, sep = "")
url_link
link_content <- GET(url_link,
user_agent(str_c(user_agent_goo, R.version$version.string, sep = ", ")),
add_headers(from = user_email))
link_content$status
url_html <- read_html(url_link)
url_code <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]') %>%
extract(seq(1,18,2)) %>%
as.character()
url_html
url_html %>%
html_nodes(xpath = './/article[@class="varios"]')
url_code <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]') %>%
extract(seq(1,16,2)) %>%
as.character()
url_code <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]') #%>%
length(url_code)
url_code0 <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]')
url_code <- url_code0 %>%
extract(seq(1, url_code0, 2)) %>%
as.character()
url_code <- url_code0 %>%
extract(seq(1, length(url_code0), 2)) %>%
as.character()
url_code1 <- sapply(strsplit(url_code, '\\/id*.'), `[`, 2)
url_code2 <- gsub('\\" .*', "", url_code1)
url_code2
library(rvest)
library(httr)
library(stringr)
library(dplyr)
library(magrittr) # extract
# SCRAPE GAMES' CODES:
scrape_new_acb_code <- function(year = 2020, compet = 1, day = 1, user_email, user_agent_goo) {
url_base <- "http://www.acb.com/resultados-clasificacion/ver/temporada_id"
url_link <- paste(url_base, "/", year, "/competicion_id/", compet, "/jornada_numero/", day, sep = "")
link_content <- GET(url_link,
user_agent(str_c(user_agent_goo, R.version$version.string, sep = ", ")),
add_headers(from = user_email))
if (link_content$status == 404) {
stop("URL not found. Please check if it exists.")
}else{
url_html <- read_html(url_link)
url_code0 <- url_html %>%
html_nodes(xpath = './/article[@class="varios"]')
url_code <- url_code0 %>%
extract(seq(1, length(url_code0), 2)) %>%
as.character()
url_code1 <- sapply(strsplit(url_code, '\\/id*.'), `[`, 2)
url_code2 <- gsub('\\" .*', "", url_code1)
return(url_code2)
}
}
user_email <- "guillermovinue@gmail.com"
user_agent_goo <- "Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0"
#days <- 1:38 ; year <- 2020 # 2020-2021
#days <- 1:23 ; year <- 2019 # 2019-2020
days <- 1:34 ; year <- 2018 # 2018-2019
codes_day <- list()
for (i in 1:length(days)) {
cat("ITERATION:", i, "\n")
cat("DAY:", days[i], "\n")
codes_day[[i]] <- scrape_new_acb_code(year = year, compet = 1, day = days[i],
user_email, user_agent_goo)
Sys.sleep(5)
}
codes_day_1819 <- codes_day
save(codes_day_1819, file = "codes_day_1819.RData")
getwd()
fechas <- c("2020-09-04", "2020-09-29", "2020-09-29", "2020-10-29", "2020-11-30",
"2020-12-31", "2021-01-29", "2021-03-01", "2021-03-30", "2021-04-29",
"2021-05-30")
pago <- c(19.96, 1.33, 16.07, 37.99, 19, 19, 38.42, 19, 48.60, 18.42, 19)
df0 <- data.frame(fecha = fechas, pago = pago)
df0
mean(df0$pago)
# Load needed packages:
library(readr)
library(dplyr)
library(countrycode)
library(BAwiR)
library(ggplot2)
# Set working directory:
setwd("~/Desktop/sports_general/paper_demogr_acb/code/output/")
# Load players' data from the last three seasons collected:
df0 <- read_csv("2018_2019/players_data_1819.csv")
df00 <- df0 %>%
select(Player, Nationality) %>%
rename(Player.x = 1) %>%
mutate(Season = "2018-2019")
df00[is.na(df00$Nationality), "Nationality"] <- "Serbia"
df1 <- read_csv("2019_2020/players_data_1920.csv")
df11 <- df1 %>%
select(Player, Nationality) %>%
rename(Player.x = 1) %>%
mutate(Season = "2019-2020") %>%
mutate_if(is.factor, as.character)
df11[is.na(df11$Nationality), "Nationality"] <- "Chile"
df11[df11$Nationality == "", "Nationality"] <- "Senegal"
df2 <- read_csv("2020_2021/players_data_2021.csv")
View(df2)
View(df2)
View(df2)
# Quino Colom is an Andorran player who have always played for Spain.
df2$Nationality[df2$Player == "J. Colom"] <- "Spain"
df22 <- df2 %>%
select(Player, Nationality) %>%
rename(Player.x = 1) %>%
mutate(Season = "2020-2021") %>%
mutate_if(is.factor, as.character)
df22[is.na(df22$Nationality), "Nationality"] <- "Dinamarca"
df3 <- rbind(df22, df11, df00)
nat_spa <- sort(unique(df3$Nationality))
nat_eng_tr <- countryname(nat_spa)
nat_spa[is.na(nat_eng_tr)]
nat_eng_tr[is.na(nat_eng_tr)] <- c("Belarus", "United States", "Guyana",
"United Kingdom", "Czech Rep.",
"Dominican Rep.", "Germany", "S. Sudan")
df4 <- df3 %>%
mutate(Nationality = plyr::mapvalues(Nationality,
from = nat_spa,
to = nat_eng_tr))
# Join with the previous seasons:
load(url("http://www.uv.es/vivigui/softw/data_app_acb.RData"))
data_acb <- rbind(df4, data_app_acb)
title <- " Number of Spanish and foreign players along the ACB seasons \n Data from www.acb.com"
get_pop_pyramid(data_acb, title, "eng") + scale_fill_grey(start = 0.5)
